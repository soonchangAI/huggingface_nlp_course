{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52a9da5-8a30-4a84-a11e-aad236b31d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████████████████████| 408/408 [00:00<00:00, 17515.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8e4b1-c359-4571-b515-b68fe7358685",
   "metadata": {},
   "source": [
    "TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da483e7-45bb-4ae3-adeb-a97b12d284d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-27 21:03:02,161] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8bbd1-aac4-4fb9-a65f-303531b2a797",
   "metadata": {},
   "source": [
    "BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9beffc20-7ef6-4f4e-a0c6-a4ae4662a734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8e54e-5714-4a94-9805-77edf6caa6e2",
   "metadata": {},
   "source": [
    "Default data_collator used by the Trainer will be a DataCollatorWithPadding as defined previously, so you can skip the line data_collator=data_collator in this call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08819479-681f-4723-80cc-82af8185e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc09628-c237-4480-8092-a1d036b19a95",
   "metadata": {},
   "source": [
    "<code>trainer.train()</code> does not evaluate because:\n",
    "* didn’t tell the Trainer to evaluate during training by setting evaluation_strategy to either \"steps\" (evaluate every eval_steps) or \"epoch\" (evaluate at the end of each epoch)\n",
    "* didn’t provide the Trainer with a compute_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b65444c4-c2c7-4980-91d1-84a6a6568fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 29/690 00:06 < 02:33, 4.30 it/s, Epoch 0.12/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/trainer.py:1888\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1886\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m scale_before \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m scale_after\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1888\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1889\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/optimization.py:466\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    462\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    468\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86274119-9f79-48d1-b6f7-6f1115a2ed87",
   "metadata": {},
   "source": [
    "Evaluation: build a <code>compute_metrics()</code> function\n",
    "* Take an <code>EvalPrediction</code> object\n",
    "  * A named tuple with a <code>predictions</code> field and a <code>label_ids</code> field\n",
    "* Returns dictionary mapping str to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c92f9a-3465-40f2-b9d0-1c37486be1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-3.0083747 ,  3.7227745 ],\n",
      "       [ 2.5148568 , -3.685114  ],\n",
      "       [-1.1738895 ,  1.4548098 ],\n",
      "       [-2.991008  ,  3.710904  ],\n",
      "       [ 2.386998  , -3.392853  ],\n",
      "       [-2.9963045 ,  3.7029953 ],\n",
      "       [-2.874949  ,  3.396956  ],\n",
      "       [-2.983798  ,  3.6950772 ],\n",
      "       [-3.0102117 ,  3.678574  ],\n",
      "       [-2.9851115 ,  3.6694648 ],\n",
      "       [-2.9817533 ,  3.6917982 ],\n",
      "       [ 0.88159555, -1.7612852 ],\n",
      "       [ 2.3181114 , -3.3687425 ],\n",
      "       [-2.9794805 ,  3.7076566 ],\n",
      "       [-2.9881742 ,  3.6889591 ],\n",
      "       [ 2.1448307 , -3.1415138 ],\n",
      "       [-2.9962258 ,  3.7037761 ],\n",
      "       [ 2.536143  , -3.567515  ],\n",
      "       [-2.9954028 ,  3.7002656 ],\n",
      "       [ 1.8065165 , -2.748624  ],\n",
      "       [ 1.8496939 , -2.8457537 ],\n",
      "       [-2.9432857 ,  3.678389  ],\n",
      "       [-2.8317778 ,  3.3713129 ],\n",
      "       [-2.9940157 ,  3.711947  ],\n",
      "       [-2.932481  ,  3.6088867 ],\n",
      "       [-2.5428913 ,  3.2481332 ],\n",
      "       [-2.3524632 ,  2.8629637 ],\n",
      "       [-3.0189471 ,  3.709275  ],\n",
      "       [-2.997495  ,  3.7031667 ],\n",
      "       [-2.9799075 ,  3.6704586 ],\n",
      "       [-1.7157686 ,  2.008424  ],\n",
      "       [-3.0276082 ,  3.7020614 ],\n",
      "       [-2.9881866 ,  3.6992137 ],\n",
      "       [-2.9871316 ,  3.72484   ],\n",
      "       [-3.008351  ,  3.7164104 ],\n",
      "       [-3.055866  ,  3.681535  ],\n",
      "       [ 2.3045008 , -3.334621  ],\n",
      "       [ 2.435049  , -3.519076  ],\n",
      "       [-2.9429908 ,  3.6412544 ],\n",
      "       [-3.0317135 ,  3.716599  ],\n",
      "       [ 2.5144293 , -3.636679  ],\n",
      "       [-3.0684807 ,  3.7339313 ],\n",
      "       [-1.9420484 ,  2.4272883 ],\n",
      "       [ 2.0142758 , -3.0809069 ],\n",
      "       [ 2.478314  , -3.5276308 ],\n",
      "       [-2.996124  ,  3.691035  ],\n",
      "       [-2.9257603 ,  3.6268697 ],\n",
      "       [ 2.4511235 , -3.4695125 ],\n",
      "       [-3.0391743 ,  3.6819437 ],\n",
      "       [-3.0166755 ,  3.7080436 ],\n",
      "       [-2.9702327 ,  3.726383  ],\n",
      "       [-2.9911535 ,  3.728895  ],\n",
      "       [-3.0205796 ,  3.7153504 ],\n",
      "       [-3.014904  ,  3.7248805 ],\n",
      "       [-2.9988277 ,  3.7208908 ],\n",
      "       [-2.9534075 ,  3.6916363 ],\n",
      "       [-2.6125996 ,  3.3206136 ],\n",
      "       [-2.9990325 ,  3.7157192 ],\n",
      "       [-3.0482767 ,  3.7170842 ],\n",
      "       [-2.9966218 ,  3.7189972 ],\n",
      "       [-2.8579884 ,  3.5753748 ],\n",
      "       [-2.877037  ,  3.5212097 ],\n",
      "       [-2.9973419 ,  3.6956453 ],\n",
      "       [-2.9736729 ,  3.6644144 ],\n",
      "       [-2.9946675 ,  3.7044814 ],\n",
      "       [ 2.3920326 , -2.9725049 ],\n",
      "       [-2.9891472 ,  3.696481  ],\n",
      "       [-3.047611  ,  3.7181861 ],\n",
      "       [ 2.3548052 , -3.3303409 ],\n",
      "       [-3.0416505 ,  3.7337859 ],\n",
      "       [-3.0292728 ,  3.6835482 ],\n",
      "       [-2.2967575 ,  2.9076712 ],\n",
      "       [-2.9927456 ,  3.695708  ],\n",
      "       [-2.9735794 ,  3.6814806 ],\n",
      "       [-2.9967551 ,  3.6993682 ],\n",
      "       [-2.969722  ,  3.6640923 ],\n",
      "       [-3.0139208 ,  3.718082  ],\n",
      "       [-3.0255816 ,  3.6968427 ],\n",
      "       [-3.0419652 ,  3.7139494 ],\n",
      "       [-3.0232415 ,  3.7310853 ],\n",
      "       [-2.7359133 ,  3.4559743 ],\n",
      "       [-2.863666  ,  3.5719042 ],\n",
      "       [-3.0403998 ,  3.7039547 ],\n",
      "       [ 1.0542684 , -2.0950875 ],\n",
      "       [-3.0124507 ,  3.7231488 ],\n",
      "       [-2.6417632 ,  3.3223634 ],\n",
      "       [-2.5309541 ,  3.1454623 ],\n",
      "       [-2.981283  ,  3.6879768 ],\n",
      "       [-3.0116143 ,  3.7067719 ],\n",
      "       [-2.9927888 ,  3.6897821 ],\n",
      "       [-2.97662   ,  3.6469216 ],\n",
      "       [-3.0060005 ,  3.7129698 ],\n",
      "       [-2.981503  ,  3.6947494 ],\n",
      "       [-2.7524266 ,  3.411559  ],\n",
      "       [-2.9791946 ,  3.708221  ],\n",
      "       [-2.9976351 ,  3.6905582 ],\n",
      "       [ 1.1688573 , -1.5218885 ],\n",
      "       [-2.9957557 ,  3.6868355 ],\n",
      "       [-2.9794972 ,  3.7227962 ],\n",
      "       [-3.0093184 ,  3.717722  ],\n",
      "       [-2.9845192 ,  3.6918378 ],\n",
      "       [ 2.442798  , -3.2730508 ],\n",
      "       [-2.921672  ,  3.5886736 ],\n",
      "       [-3.0307677 ,  3.7079327 ],\n",
      "       [-1.3337091 ,  1.5682358 ],\n",
      "       [-3.0354517 ,  3.6756642 ],\n",
      "       [-2.7731278 ,  3.402935  ],\n",
      "       [ 0.8293284 , -1.838804  ],\n",
      "       [ 1.6458898 , -2.7015839 ],\n",
      "       [-3.0616162 ,  3.7194774 ],\n",
      "       [-2.9493644 ,  3.670399  ],\n",
      "       [-2.9861178 ,  3.6738486 ],\n",
      "       [-2.9823935 ,  3.6502354 ],\n",
      "       [-2.9856794 ,  3.6947854 ],\n",
      "       [-2.8724043 ,  3.609839  ],\n",
      "       [-2.6909678 ,  3.2769775 ],\n",
      "       [-2.9987257 ,  3.6906216 ],\n",
      "       [-2.948249  ,  3.6546602 ],\n",
      "       [-3.021061  ,  3.6841488 ],\n",
      "       [-3.032359  ,  3.7162178 ],\n",
      "       [-2.9875145 ,  3.6703413 ],\n",
      "       [-2.9450095 ,  3.6840255 ],\n",
      "       [ 0.9630291 , -1.7651205 ],\n",
      "       [-3.002978  ,  3.61897   ],\n",
      "       [-3.018468  ,  3.7168295 ],\n",
      "       [-2.9809544 ,  3.695861  ],\n",
      "       [-3.0094311 ,  3.720484  ],\n",
      "       [ 2.5056279 , -3.6615884 ],\n",
      "       [-3.0010252 ,  3.7097197 ],\n",
      "       [-3.0297284 ,  3.731568  ],\n",
      "       [-3.0008388 ,  3.7108452 ],\n",
      "       [-2.9787674 ,  3.6946924 ],\n",
      "       [-2.984078  ,  3.6980658 ],\n",
      "       [-0.5317816 ,  0.18719192],\n",
      "       [-2.9170694 ,  3.6795757 ],\n",
      "       [-2.9884336 ,  3.6860995 ],\n",
      "       [-2.9139278 ,  3.6750042 ],\n",
      "       [ 2.4896798 , -3.2628052 ],\n",
      "       [-2.998085  ,  3.696383  ],\n",
      "       [-2.9831033 ,  3.7132666 ],\n",
      "       [-2.9855754 ,  3.6991608 ],\n",
      "       [-2.7428277 ,  3.2781184 ],\n",
      "       [ 2.579832  , -3.695661  ],\n",
      "       [-3.0411022 ,  3.67908   ],\n",
      "       [ 2.466305  , -3.607361  ],\n",
      "       [-2.9237401 ,  3.5800886 ],\n",
      "       [-2.9960647 ,  3.690495  ],\n",
      "       [-2.902332  ,  3.6216364 ],\n",
      "       [-2.8132071 ,  3.4747941 ],\n",
      "       [-2.9924576 ,  3.7039783 ],\n",
      "       [ 2.569651  , -3.6743572 ],\n",
      "       [-2.9133592 ,  3.6357152 ],\n",
      "       [-3.0223434 ,  3.710195  ],\n",
      "       [-2.9836805 ,  3.7127645 ],\n",
      "       [ 1.3592458 , -2.3096254 ],\n",
      "       [-2.9997134 ,  3.7226152 ],\n",
      "       [-3.0660832 ,  3.7416453 ],\n",
      "       [-2.9050355 ,  3.62235   ],\n",
      "       [ 1.4117401 , -2.2015274 ],\n",
      "       [-3.0582058 ,  3.707596  ],\n",
      "       [-3.0361555 ,  3.7266417 ],\n",
      "       [-2.9969296 ,  3.690196  ],\n",
      "       [-2.9881005 ,  3.6973696 ],\n",
      "       [-2.988028  ,  3.693112  ],\n",
      "       [-2.9861913 ,  3.6722677 ],\n",
      "       [-2.967185  ,  3.6860468 ],\n",
      "       [-3.0180504 ,  3.7365448 ],\n",
      "       [-2.702623  ,  3.22392   ],\n",
      "       [-2.9860954 ,  3.697542  ],\n",
      "       [-1.6457736 ,  2.064152  ],\n",
      "       [ 2.3756292 , -3.4104545 ],\n",
      "       [-2.9132152 ,  3.698238  ],\n",
      "       [-2.9573827 ,  3.688412  ],\n",
      "       [-2.9946468 ,  3.7202675 ],\n",
      "       [-2.9632306 ,  3.7036855 ],\n",
      "       [-3.026448  ,  3.7144938 ],\n",
      "       [-2.9828613 ,  3.6813087 ],\n",
      "       [ 2.055869  , -3.158779  ],\n",
      "       [-3.0021386 ,  3.681639  ],\n",
      "       [-3.012076  ,  3.7046845 ],\n",
      "       [ 1.654106  , -2.6202784 ],\n",
      "       [-2.3504379 ,  2.7995343 ],\n",
      "       [-2.9566338 ,  3.665888  ],\n",
      "       [-3.0001402 ,  3.7074966 ],\n",
      "       [-2.4827077 ,  3.01343   ],\n",
      "       [-2.9293237 ,  3.5440319 ],\n",
      "       [ 2.486619  , -3.3892674 ],\n",
      "       [-2.2538517 ,  2.7361333 ],\n",
      "       [ 2.2981174 , -3.3611808 ],\n",
      "       [-2.9702966 ,  3.687423  ],\n",
      "       [-3.0112984 ,  3.7029204 ],\n",
      "       [ 2.1690998 , -3.2059448 ],\n",
      "       [-2.2564723 ,  2.7522604 ],\n",
      "       [-2.9787908 ,  3.682761  ],\n",
      "       [-2.7163267 ,  3.3762648 ],\n",
      "       [-2.8864977 ,  3.6325758 ],\n",
      "       [-3.0031698 ,  3.6902192 ],\n",
      "       [-2.900133  ,  3.6299317 ],\n",
      "       [-2.9285402 ,  3.6706583 ],\n",
      "       [-3.0081382 ,  3.7222345 ],\n",
      "       [-3.019605  ,  3.7143078 ],\n",
      "       [-2.6648676 ,  3.336515  ],\n",
      "       [-2.8148046 ,  3.5755258 ],\n",
      "       [-2.9565594 ,  3.667699  ],\n",
      "       [-2.947831  ,  3.650333  ],\n",
      "       [-0.6998986 ,  0.55087966],\n",
      "       [-3.0283122 ,  3.7227714 ],\n",
      "       [-2.976999  ,  3.682855  ],\n",
      "       [ 2.297452  , -3.3148386 ],\n",
      "       [ 0.35133824, -0.4495465 ],\n",
      "       [-2.3554513 ,  3.068903  ],\n",
      "       [-3.0002434 ,  3.7057703 ],\n",
      "       [-2.8569963 ,  3.602785  ],\n",
      "       [ 2.4057612 , -3.4009252 ],\n",
      "       [-2.9316077 ,  3.639445  ],\n",
      "       [-3.0052042 ,  3.7005842 ],\n",
      "       [-3.0301096 ,  3.671894  ],\n",
      "       [-3.0303001 ,  3.7219784 ],\n",
      "       [ 2.2303686 , -3.2627327 ],\n",
      "       [-2.9798715 ,  3.7159655 ],\n",
      "       [-2.9918668 ,  3.6970234 ],\n",
      "       [-2.7651234 ,  3.3663285 ],\n",
      "       [-3.0256236 ,  3.7206616 ],\n",
      "       [ 2.602949  , -3.7447252 ],\n",
      "       [-2.980377  ,  3.691487  ],\n",
      "       [-3.0090916 ,  3.6869907 ],\n",
      "       [-3.0368805 ,  3.7234652 ],\n",
      "       [-2.9580054 ,  3.6491337 ],\n",
      "       [-2.9802787 ,  3.7042174 ],\n",
      "       [-3.0804038 ,  3.7381496 ],\n",
      "       [-3.0373588 ,  3.7320724 ],\n",
      "       [-3.003351  ,  3.682636  ],\n",
      "       [-2.9330857 ,  3.6126304 ],\n",
      "       [ 1.5441207 , -1.9236516 ],\n",
      "       [-2.8131895 ,  3.456929  ],\n",
      "       [-1.9964956 ,  2.506758  ],\n",
      "       [-3.0004618 ,  3.7187803 ],\n",
      "       [ 2.4369938 , -3.4722035 ],\n",
      "       [-2.8952296 ,  3.6333218 ],\n",
      "       [-2.8518176 ,  3.576191  ],\n",
      "       [-2.992141  ,  3.663231  ],\n",
      "       [ 1.4035941 , -2.3113112 ],\n",
      "       [-2.9051108 ,  3.6236598 ],\n",
      "       [-2.9439619 ,  3.6213841 ],\n",
      "       [-3.0294669 ,  3.7321985 ],\n",
      "       [-3.0249972 ,  3.7027361 ],\n",
      "       [-2.9850903 ,  3.674692  ],\n",
      "       [-2.944748  ,  3.6931458 ],\n",
      "       [-2.9982874 ,  3.702819  ],\n",
      "       [-2.988099  ,  3.6727145 ],\n",
      "       [-2.998617  ,  3.706073  ],\n",
      "       [ 1.5290134 , -2.5457437 ],\n",
      "       [-0.40544602,  0.22479619],\n",
      "       [-2.9412181 ,  3.6325104 ],\n",
      "       [-2.5778012 ,  3.2124314 ],\n",
      "       [ 2.235495  , -3.3122637 ],\n",
      "       [-3.0072436 ,  3.723668  ],\n",
      "       [-3.0488794 ,  3.7197924 ],\n",
      "       [-2.9980206 ,  3.694977  ],\n",
      "       [ 1.4366465 , -2.1143684 ],\n",
      "       [-3.0238383 ,  3.6748574 ],\n",
      "       [-2.723354  ,  3.3124146 ],\n",
      "       [-3.0066874 ,  3.6942348 ],\n",
      "       [-2.901316  ,  3.5965035 ],\n",
      "       [-2.9504976 ,  3.6745496 ],\n",
      "       [-2.7095315 ,  3.3550384 ],\n",
      "       [-2.9647126 ,  3.659865  ],\n",
      "       [ 1.0853461 , -1.7287288 ],\n",
      "       [-2.6371696 ,  3.1830752 ],\n",
      "       [-3.0429034 ,  3.7199252 ],\n",
      "       [-0.66647154,  0.38501373],\n",
      "       [-2.971495  ,  3.6762598 ],\n",
      "       [-2.9988043 ,  3.710405  ],\n",
      "       [-3.039213  ,  3.7022882 ],\n",
      "       [-2.995531  ,  3.6844373 ],\n",
      "       [-2.9929998 ,  3.6875591 ],\n",
      "       [-3.0310888 ,  3.73469   ],\n",
      "       [ 1.9628043 , -2.7347753 ],\n",
      "       [-2.9700313 ,  3.60918   ],\n",
      "       [ 2.6171947 , -3.6031582 ],\n",
      "       [-3.0224724 ,  3.7412956 ],\n",
      "       [-2.9226825 ,  3.6469371 ],\n",
      "       [-2.956917  ,  3.6369047 ],\n",
      "       [ 1.2520641 , -1.5331444 ],\n",
      "       [ 1.8597931 , -2.5303097 ],\n",
      "       [-3.0415752 ,  3.7174568 ],\n",
      "       [-2.9895558 ,  3.699201  ],\n",
      "       [-0.80704683,  0.9930961 ],\n",
      "       [-3.0048153 ,  3.6983805 ],\n",
      "       [-1.1569874 ,  1.1461949 ],\n",
      "       [-2.9410844 ,  3.688759  ],\n",
      "       [ 2.0133617 , -3.0417485 ],\n",
      "       [-3.0080433 ,  3.7059536 ],\n",
      "       [-3.01619   ,  3.691707  ],\n",
      "       [-2.5458667 ,  3.1962512 ],\n",
      "       [ 2.3409011 , -3.43996   ],\n",
      "       [-0.6581154 ,  0.48711246],\n",
      "       [-2.9642327 ,  3.7170215 ],\n",
      "       [-3.0030155 ,  3.7043364 ],\n",
      "       [-2.9299963 ,  3.6478088 ],\n",
      "       [-3.0191765 ,  3.7172368 ],\n",
      "       [-3.014933  ,  3.691767  ],\n",
      "       [-3.0086248 ,  3.6840587 ],\n",
      "       [ 1.0268829 , -1.8125392 ],\n",
      "       [-2.929233  ,  3.6604826 ],\n",
      "       [-3.024273  ,  3.7166429 ],\n",
      "       [ 2.6023355 , -3.6389303 ],\n",
      "       [-3.018424  ,  3.707672  ],\n",
      "       [ 2.7128305 , -3.5150888 ],\n",
      "       [-2.5317378 ,  3.166801  ],\n",
      "       [-3.0027318 ,  3.7071311 ],\n",
      "       [-3.0102503 ,  3.6890204 ],\n",
      "       [ 0.3111296 , -0.91974384],\n",
      "       [ 2.4931264 , -3.651995  ],\n",
      "       [-2.989505  ,  3.6982808 ],\n",
      "       [-0.38076285,  0.12402689],\n",
      "       [-2.99979   ,  3.6727772 ],\n",
      "       [-3.0194776 ,  3.7018883 ],\n",
      "       [ 1.6507614 , -2.6954463 ],\n",
      "       [-2.8944616 ,  3.5635178 ],\n",
      "       [ 1.9664603 , -2.9837356 ],\n",
      "       [ 2.4519815 , -3.5309365 ],\n",
      "       [ 2.565148  , -3.69667   ],\n",
      "       [-2.9504604 ,  3.6549537 ],\n",
      "       [-2.35856   ,  2.9726446 ],\n",
      "       [-3.0229368 ,  3.7051954 ],\n",
      "       [-2.9398596 ,  3.6615093 ],\n",
      "       [-2.9860368 ,  3.6908975 ],\n",
      "       [-3.0419981 ,  3.6856692 ],\n",
      "       [-2.9519477 ,  3.6390858 ],\n",
      "       [-2.9753354 ,  3.6883578 ],\n",
      "       [-2.9916089 ,  3.6993554 ],\n",
      "       [-1.665181  ,  2.2233562 ],\n",
      "       [-2.941244  ,  3.642593  ],\n",
      "       [-3.005671  ,  3.689631  ],\n",
      "       [-2.7633274 ,  3.4128056 ],\n",
      "       [-3.0518925 ,  3.7455072 ],\n",
      "       [-2.9516506 ,  3.6600897 ],\n",
      "       [ 2.336853  , -3.4464605 ],\n",
      "       [-2.9774914 ,  3.6551416 ],\n",
      "       [-3.0153015 ,  3.6943    ],\n",
      "       [-2.9664547 ,  3.6668663 ],\n",
      "       [ 2.681957  , -3.5450974 ],\n",
      "       [-2.9777653 ,  3.6974454 ],\n",
      "       [-2.9801028 ,  3.692828  ],\n",
      "       [-2.9875033 ,  3.6910083 ],\n",
      "       [-3.038701  ,  3.7217236 ],\n",
      "       [-3.0134182 ,  3.6993499 ],\n",
      "       [-2.89239   ,  3.5990524 ],\n",
      "       [-2.9720845 ,  3.6902127 ],\n",
      "       [ 2.3225753 , -3.2893631 ],\n",
      "       [-2.9895115 ,  3.6933615 ],\n",
      "       [-2.8890758 ,  3.5944111 ],\n",
      "       [-2.9677503 ,  3.6580656 ],\n",
      "       [-1.4402901 ,  1.5680232 ],\n",
      "       [-2.6208649 ,  3.3191607 ],\n",
      "       [-3.0157273 ,  3.7349532 ],\n",
      "       [-2.9019082 ,  3.6476488 ],\n",
      "       [-3.0014713 ,  3.673809  ],\n",
      "       [-3.004353  ,  3.739719  ],\n",
      "       [ 2.5521054 , -3.6218035 ],\n",
      "       [-3.0261624 ,  3.730356  ],\n",
      "       [-2.986265  ,  3.6994872 ],\n",
      "       [-2.8398275 ,  3.6108832 ],\n",
      "       [-2.9049714 ,  3.6073072 ],\n",
      "       [-2.9754653 ,  3.6889286 ],\n",
      "       [-2.981845  ,  3.6963809 ],\n",
      "       [-2.9026906 ,  3.583807  ],\n",
      "       [ 2.2181706 , -3.1160238 ],\n",
      "       [ 2.1818016 , -3.1581862 ],\n",
      "       [-2.8587775 ,  3.5006576 ],\n",
      "       [-2.9973042 ,  3.735071  ],\n",
      "       [-2.903621  ,  3.5780392 ],\n",
      "       [-2.921922  ,  3.6972404 ],\n",
      "       [-1.2571915 ,  1.4679103 ],\n",
      "       [ 2.6574275 , -3.4558084 ],\n",
      "       [-2.777237  ,  3.460049  ],\n",
      "       [ 2.4308548 , -3.462445  ],\n",
      "       [-2.9933627 ,  3.692853  ],\n",
      "       [-3.0465448 ,  3.709327  ],\n",
      "       [-3.011605  ,  3.726855  ],\n",
      "       [-2.9908788 ,  3.6976252 ],\n",
      "       [ 2.2891576 , -3.3170311 ],\n",
      "       [-2.9880617 ,  3.699134  ],\n",
      "       [-2.9525623 ,  3.650453  ],\n",
      "       [ 1.4491049 , -2.4067757 ],\n",
      "       [-2.9636219 ,  3.6711674 ],\n",
      "       [-3.0041199 ,  3.7240376 ],\n",
      "       [-2.9892995 ,  3.678526  ],\n",
      "       [ 2.4018252 , -3.409094  ],\n",
      "       [-2.9980304 ,  3.70904   ],\n",
      "       [-2.7050917 ,  3.389736  ],\n",
      "       [-2.9877026 ,  3.698922  ],\n",
      "       [-2.9816887 ,  3.687386  ],\n",
      "       [-3.0115023 ,  3.6957886 ],\n",
      "       [-2.9602807 ,  3.6648521 ],\n",
      "       [-3.0427735 ,  3.7084901 ],\n",
      "       [-2.5914423 ,  3.2857    ],\n",
      "       [-2.5825775 ,  3.1042998 ],\n",
      "       [-2.989106  ,  3.6841671 ],\n",
      "       [ 2.4345741 , -3.5087633 ],\n",
      "       [-3.0053816 ,  3.7012272 ],\n",
      "       [-2.9706862 ,  3.6707923 ],\n",
      "       [ 2.435802  , -3.550123  ],\n",
      "       [-2.6926837 ,  3.3970845 ],\n",
      "       [-3.0004406 ,  3.7025826 ],\n",
      "       [-2.5097146 ,  3.1493208 ],\n",
      "       [-3.0204854 ,  3.7127066 ]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.947718620300293, 'test_runtime': 2.5785, 'test_samples_per_second': 158.229, 'test_steps_per_second': 10.083})\n",
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a355c-e3c6-426b-9bc9-05ecabdb1aca",
   "metadata": {},
   "source": [
    "<code>predict()</code> outputs named tuple with 3 fields: predictions, label_ids & metrics\n",
    "* metrics: loss & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6dff8d-7503-4cec-a025-97aa30e20bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predictions to labels\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "preds[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f664b95-b12c-4c78-baad-f8b0d1439db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.label_ids[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be131192-4e3a-42bf-b8fa-a78b80d9a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.75k/5.75k [00:00<00:00, 2.41MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8235294117647058, 'f1': 0.8823529411764706}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\",\"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582b76b-5c07-4657-9b48-8101d8c3b4b7",
   "metadata": {},
   "source": [
    "Result varies due to random initialization of the model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc42d9a6-d634-4146-a62d-189041adbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\",\"mrpc\") # get metric\n",
    "    logits, labels = eval_preds # predicted logits & labels\n",
    "    predictions = np.argmax(logits, axis=-1) # the argmax\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f2082c9-21e2-44fb-a692-0171aed9d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\",evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59259d6d-f6f0-4e44-bc6a-63c7ba964f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 03:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372311</td>\n",
       "      <td>0.835784</td>\n",
       "      <td>0.878403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.390433</td>\n",
       "      <td>0.855392</td>\n",
       "      <td>0.900169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.518771</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>0.905009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.33592849399732505, metrics={'train_runtime': 192.7801, 'train_samples_per_second': 57.081, 'train_steps_per_second': 3.579, 'total_flos': 430433242128000.0, 'train_loss': 0.33592849399732505, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7b46c-f80f-4744-94b4-0dd9b431bff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc40676-9c56-4c3d-92f9-34c52b157cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
