{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fb60bc-a078-440e-9490-f4745f8d8a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|████████████████████████| 3668/3668 [00:00<00:00, 14670.22 examples/s]\n",
      "Map: 100%|██████████████████████████| 408/408 [00:00<00:00, 18665.55 examples/s]\n",
      "Map: 100%|████████████████████████| 1725/1725 [00:00<00:00, 24191.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12acc4a0-ee34-455b-8658-09652bcf0b06",
   "metadata": {},
   "source": [
    "* Define a **TrainingArguments** class\n",
    "  * hyperparameters, directories etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143d372c-1aa9-4e57-ada4-d945f84d96ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 14:10:26,238] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271b9b7d-3e9a-4c04-bce9-cde0ede6d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc3eff-4fa6-40b9-af4b-2d184b7627f3",
   "metadata": {},
   "source": [
    "* A new classifier head is added, randomly iinitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd83897-1e1a-4fc6-b7f5-d7ed84d9a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args, \n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00dc72b7-e5ac-4a1f-b099-808a8139187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msoonchangpoh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/cybertron/fa54fcb6-b5e1-492e-978a-6389519c168a/huggingface_nlp_course/notebooks/wandb/run-20231217_141033-6329znch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/soonchangpoh/huggingface/runs/6329znch' target=\"_blank\">skilled-hill-16</a></strong> to <a href='https://wandb.ai/soonchangpoh/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/soonchangpoh/huggingface' target=\"_blank\">https://wandb.ai/soonchangpoh/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/soonchangpoh/huggingface/runs/6329znch' target=\"_blank\">https://wandb.ai/soonchangpoh/huggingface/runs/6329znch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 02:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.377500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.3076247173806895, metrics={'train_runtime': 175.3183, 'train_samples_per_second': 62.766, 'train_steps_per_second': 3.936, 'total_flos': 430291408824720.0, 'train_loss': 0.3076247173806895, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a88169-7707-4b67-a20d-022d00e3f0c8",
   "metadata": {},
   "source": [
    "**compute_metric()**\n",
    "* Input: EvalPrediction (tuple with **predictions** & **label_ids**)\n",
    "* Return: Dictionary with key (name of metric) and val (float value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0d7f4e-957f-4bb0-862e-b236aee7bc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2)\n",
      "(408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets['validation'])\n",
    "print(predictions.predictions.shape)\n",
    "print(predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c68753f-505f-405a-97ef-95ae32b2e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.8333833e+00,  2.8015301e+00],\n",
       "       [ 2.9464595e+00, -3.0162218e+00],\n",
       "       [ 1.9412735e+00, -1.6329376e+00],\n",
       "       [-2.7756567e+00,  2.8011887e+00],\n",
       "       [ 2.6230412e+00, -2.8055775e+00],\n",
       "       [-2.7766528e+00,  2.7675545e+00],\n",
       "       [-2.5183961e+00,  2.2145400e+00],\n",
       "       [-2.7911282e+00,  2.7915554e+00],\n",
       "       [-2.7402694e+00,  2.7176280e+00],\n",
       "       [-2.7931893e+00,  2.7988048e+00],\n",
       "       [-2.7837543e+00,  2.7844136e+00],\n",
       "       [ 2.8804936e+00, -2.8534677e+00],\n",
       "       [ 2.3489616e+00, -2.0654774e+00],\n",
       "       [-2.7230930e+00,  2.7047725e+00],\n",
       "       [-2.8122118e+00,  2.7996569e+00],\n",
       "       [ 1.9923896e+00, -2.3156464e+00],\n",
       "       [-2.7836628e+00,  2.7994080e+00],\n",
       "       [ 1.6739997e+00, -1.3882061e+00],\n",
       "       [-2.7840524e+00,  2.7974110e+00],\n",
       "       [ 2.3737619e+00, -2.2511227e+00],\n",
       "       [ 2.2953274e+00, -2.5455713e+00],\n",
       "       [-2.7319446e+00,  2.6170747e+00],\n",
       "       [ 2.0457239e+00, -2.2287965e+00],\n",
       "       [-2.7596602e+00,  2.7559462e+00],\n",
       "       [-2.7575219e+00,  2.7940032e+00],\n",
       "       [-1.4596168e+00,  1.3635055e+00],\n",
       "       [-3.1453572e-02, -1.3207114e-01],\n",
       "       [-2.8297758e+00,  2.7915161e+00],\n",
       "       [-2.5261335e+00,  2.4203868e+00],\n",
       "       [-2.7833488e+00,  2.7781222e+00],\n",
       "       [ 2.0614197e+00, -2.3104897e+00],\n",
       "       [-2.7683742e+00,  2.7983668e+00],\n",
       "       [-2.6580830e+00,  2.4880421e+00],\n",
       "       [-2.6470287e+00,  2.5001113e+00],\n",
       "       [-2.8178377e+00,  2.8085103e+00],\n",
       "       [-2.6904335e+00,  2.5489359e+00],\n",
       "       [ 2.6180215e+00, -2.7624414e+00],\n",
       "       [ 2.5767529e+00, -2.4734561e+00],\n",
       "       [-2.4296882e+00,  2.3606408e+00],\n",
       "       [-2.8091476e+00,  2.7869537e+00],\n",
       "       [ 2.5595920e+00, -2.4290733e+00],\n",
       "       [-2.8644986e+00,  2.7760980e+00],\n",
       "       [ 1.9998630e+00, -2.2591724e+00],\n",
       "       [ 1.5707005e+00, -1.4608566e+00],\n",
       "       [ 2.0001819e+00, -1.6969081e+00],\n",
       "       [-2.7801526e+00,  2.8090556e+00],\n",
       "       [-2.7511582e+00,  2.7925739e+00],\n",
       "       [ 2.6409888e+00, -2.8388901e+00],\n",
       "       [-2.8062365e+00,  2.7978539e+00],\n",
       "       [-2.8048840e+00,  2.7907937e+00],\n",
       "       [-2.8005264e+00,  2.6547673e+00],\n",
       "       [-2.7719464e+00,  2.7634807e+00],\n",
       "       [-2.7931280e+00,  2.8054631e+00],\n",
       "       [-2.7959428e+00,  2.8012173e+00],\n",
       "       [-2.7602305e+00,  2.7934597e+00],\n",
       "       [-2.8269036e+00,  2.7708731e+00],\n",
       "       [-2.0563958e+00,  1.6998569e+00],\n",
       "       [-2.7763739e+00,  2.8009093e+00],\n",
       "       [-2.8702507e+00,  2.8016958e+00],\n",
       "       [-2.6878467e+00,  2.6897476e+00],\n",
       "       [-2.8008406e+00,  2.6812046e+00],\n",
       "       [-1.0017654e+00,  8.9340001e-01],\n",
       "       [-2.7738397e+00,  2.7970338e+00],\n",
       "       [-2.8123076e+00,  2.7696772e+00],\n",
       "       [-2.7561128e+00,  2.7245741e+00],\n",
       "       [ 1.2826787e+00, -8.9544368e-01],\n",
       "       [-2.7623701e+00,  2.7897289e+00],\n",
       "       [-2.8370435e+00,  2.8034980e+00],\n",
       "       [ 2.0963383e+00, -1.9055327e+00],\n",
       "       [-2.8098040e+00,  2.7933562e+00],\n",
       "       [-2.7989509e+00,  2.7852707e+00],\n",
       "       [ 1.2501854e+00, -8.0134046e-01],\n",
       "       [-2.7775540e+00,  2.7958210e+00],\n",
       "       [-2.7728436e+00,  2.7761784e+00],\n",
       "       [-2.6595652e+00,  2.6001143e+00],\n",
       "       [-2.7838104e+00,  2.7069561e+00],\n",
       "       [-2.8624120e+00,  2.7718732e+00],\n",
       "       [-2.7484441e+00,  2.7840898e+00],\n",
       "       [-2.8411083e+00,  2.7802305e+00],\n",
       "       [-2.8475041e+00,  2.7486613e+00],\n",
       "       [-2.6740425e+00,  2.5901911e+00],\n",
       "       [-2.7114046e+00,  2.6671185e+00],\n",
       "       [-2.8293233e+00,  2.7770052e+00],\n",
       "       [ 2.7929909e+00, -3.0598629e+00],\n",
       "       [-2.8170309e+00,  2.7942200e+00],\n",
       "       [-2.2002296e+00,  2.1457176e+00],\n",
       "       [-2.7499602e+00,  2.7347505e+00],\n",
       "       [-2.3426628e+00,  2.0169983e+00],\n",
       "       [-2.7773240e+00,  2.8017361e+00],\n",
       "       [-2.7938924e+00,  2.7991531e+00],\n",
       "       [ 2.4709845e+00, -2.3570797e+00],\n",
       "       [-2.7706707e+00,  2.8031545e+00],\n",
       "       [-2.8041866e+00,  2.7868893e+00],\n",
       "       [-2.7578006e+00,  2.7793083e+00],\n",
       "       [-2.7865851e+00,  2.7939882e+00],\n",
       "       [-2.8039596e+00,  2.7553544e+00],\n",
       "       [ 1.7627388e+00, -1.8399869e+00],\n",
       "       [-2.7461288e+00,  2.7548962e+00],\n",
       "       [-2.7007604e+00,  2.7174048e+00],\n",
       "       [-2.7660398e+00,  2.7909107e+00],\n",
       "       [-2.7699978e+00,  2.7884667e+00],\n",
       "       [-2.3180542e+00,  2.0880952e+00],\n",
       "       [-2.7630353e+00,  2.7693818e+00],\n",
       "       [-2.8362579e+00,  2.7974544e+00],\n",
       "       [ 2.1385760e+00, -2.2061961e+00],\n",
       "       [-2.8291867e+00,  2.7554426e+00],\n",
       "       [ 4.3983439e-01, -7.5208718e-01],\n",
       "       [ 2.6926978e+00, -2.8416097e+00],\n",
       "       [ 2.2823086e+00, -2.2751472e+00],\n",
       "       [-2.7879376e+00,  2.7754920e+00],\n",
       "       [-2.7233472e+00,  2.6197755e+00],\n",
       "       [-2.7283182e+00,  2.7814903e+00],\n",
       "       [-2.7688417e+00,  2.7889264e+00],\n",
       "       [-2.7657659e+00,  2.7899506e+00],\n",
       "       [-2.3827221e+00,  2.2653396e+00],\n",
       "       [ 2.3529198e+00, -2.1363986e+00],\n",
       "       [-2.7963088e+00,  2.7846243e+00],\n",
       "       [-2.7614551e+00,  2.7846859e+00],\n",
       "       [-2.7578018e+00,  2.7838006e+00],\n",
       "       [-2.8368797e+00,  2.7969630e+00],\n",
       "       [-2.7631013e+00,  2.7956748e+00],\n",
       "       [-2.6051004e+00,  2.5834568e+00],\n",
       "       [ 2.3135023e+00, -2.4254029e+00],\n",
       "       [-2.7310886e+00,  2.6697080e+00],\n",
       "       [-2.8117874e+00,  2.8000286e+00],\n",
       "       [-2.7861719e+00,  2.7819250e+00],\n",
       "       [-2.8359230e+00,  2.7839487e+00],\n",
       "       [ 2.5777488e+00, -2.5936434e+00],\n",
       "       [-2.7925181e+00,  2.8004198e+00],\n",
       "       [-2.8331347e+00,  2.7665260e+00],\n",
       "       [-2.7631826e+00,  2.7990844e+00],\n",
       "       [ 2.7888125e-01, -5.0826699e-01],\n",
       "       [-2.7532179e+00,  2.7746727e+00],\n",
       "       [ 2.3571107e+00, -2.5324628e+00],\n",
       "       [-2.6291907e+00,  2.2626688e+00],\n",
       "       [-2.7611072e+00,  2.7143812e+00],\n",
       "       [-2.6389995e+00,  2.4389892e+00],\n",
       "       [ 2.7247815e+00, -2.6083999e+00],\n",
       "       [-2.7981517e+00,  2.8102105e+00],\n",
       "       [-2.7803233e+00,  2.8000839e+00],\n",
       "       [-2.7866576e+00,  2.7956502e+00],\n",
       "       [ 1.4256558e+00, -1.3735961e+00],\n",
       "       [ 2.9621630e+00, -3.0076978e+00],\n",
       "       [-2.8308380e+00,  2.7796364e+00],\n",
       "       [ 2.8844783e+00, -2.9213700e+00],\n",
       "       [-2.5069098e+00,  2.3690476e+00],\n",
       "       [-2.7703397e+00,  2.7982368e+00],\n",
       "       [-8.2238626e-01,  4.2628348e-01],\n",
       "       [ 1.3827199e+00, -1.1917562e+00],\n",
       "       [-2.7493594e+00,  2.7509286e+00],\n",
       "       [ 2.7692630e+00, -2.9225211e+00],\n",
       "       [-2.6989684e+00,  2.6919155e+00],\n",
       "       [-2.8087211e+00,  2.7740557e+00],\n",
       "       [-2.7467124e+00,  2.7694087e+00],\n",
       "       [-1.4334435e+00,  1.1724966e+00],\n",
       "       [-2.7926455e+00,  2.7888963e+00],\n",
       "       [-2.8527102e+00,  2.7750947e+00],\n",
       "       [-2.6867208e+00,  2.5641654e+00],\n",
       "       [ 2.2835708e+00, -1.9783968e+00],\n",
       "       [-2.7480867e+00,  2.6996486e+00],\n",
       "       [-2.7478683e+00,  2.7566948e+00],\n",
       "       [-2.8092110e+00,  2.7484837e+00],\n",
       "       [-2.7780623e+00,  2.7937682e+00],\n",
       "       [-2.7682323e+00,  2.7900538e+00],\n",
       "       [-2.8359768e+00,  2.7605872e+00],\n",
       "       [-2.8117769e+00,  2.7965744e+00],\n",
       "       [-2.7866905e+00,  2.7700770e+00],\n",
       "       [-2.6886241e+00,  2.5444713e+00],\n",
       "       [-2.7562122e+00,  2.7434287e+00],\n",
       "       [ 2.5072477e+00, -2.3895402e+00],\n",
       "       [-1.2281531e-01,  2.4181174e-01],\n",
       "       [-1.4726366e+00,  1.3286958e+00],\n",
       "       [-1.4800254e+00,  1.4122330e+00],\n",
       "       [-2.7854171e+00,  2.7836790e+00],\n",
       "       [-2.7968295e+00,  2.7842171e+00],\n",
       "       [-2.7995527e+00,  2.7781634e+00],\n",
       "       [-2.7606359e+00,  2.7831178e+00],\n",
       "       [ 2.0682175e+00, -2.0068617e+00],\n",
       "       [-2.7407684e+00,  2.7679880e+00],\n",
       "       [-2.7860124e+00,  2.8114121e+00],\n",
       "       [ 1.4631718e+00, -1.4470737e+00],\n",
       "       [-1.5472430e+00,  1.2693272e+00],\n",
       "       [-2.7474065e+00,  2.7952514e+00],\n",
       "       [-2.7701311e+00,  2.7597907e+00],\n",
       "       [-4.7595459e-01,  1.7427798e-01],\n",
       "       [-2.7192175e+00,  2.6746082e+00],\n",
       "       [ 2.8857148e+00, -3.0121734e+00],\n",
       "       [ 1.6766442e+00, -2.0143390e+00],\n",
       "       [ 2.7724447e+00, -2.9122553e+00],\n",
       "       [-2.7123396e+00,  2.5895524e+00],\n",
       "       [-2.8136079e+00,  2.8092914e+00],\n",
       "       [ 2.6944788e+00, -2.8723946e+00],\n",
       "       [ 1.8056341e+00, -1.5769843e+00],\n",
       "       [-2.7623703e+00,  2.7916729e+00],\n",
       "       [-1.1079458e+00,  1.1016821e+00],\n",
       "       [-2.7530179e+00,  2.7333624e+00],\n",
       "       [-2.7638679e+00,  2.7971089e+00],\n",
       "       [-1.2222888e+00,  7.8840476e-01],\n",
       "       [-2.7732480e+00,  2.6656275e+00],\n",
       "       [-2.7677662e+00,  2.7770524e+00],\n",
       "       [-2.7937057e+00,  2.7626946e+00],\n",
       "       [-2.5179417e+00,  2.3929894e+00],\n",
       "       [-1.2485906e-01,  2.8498548e-01],\n",
       "       [-2.7862997e+00,  2.7747881e+00],\n",
       "       [-2.7583125e+00,  2.7242196e+00],\n",
       "       [ 2.5984409e+00, -2.4780567e+00],\n",
       "       [-2.8071349e+00,  2.7906761e+00],\n",
       "       [-2.8485634e+00,  2.6935163e+00],\n",
       "       [ 2.6449699e+00, -2.7192740e+00],\n",
       "       [ 2.5316463e+00, -2.5547600e+00],\n",
       "       [-1.2691772e+00,  1.1709700e+00],\n",
       "       [-2.7621942e+00,  2.7880263e+00],\n",
       "       [-1.7321632e+00,  1.5818938e+00],\n",
       "       [ 2.5816345e+00, -2.5715275e+00],\n",
       "       [-2.7695620e+00,  2.7901678e+00],\n",
       "       [-2.8090744e+00,  2.8111973e+00],\n",
       "       [-2.7877080e+00,  2.7652104e+00],\n",
       "       [-2.8532023e+00,  2.7245152e+00],\n",
       "       [ 2.5542486e+00, -2.6782370e+00],\n",
       "       [-2.7004793e+00,  2.6735401e+00],\n",
       "       [-2.7981699e+00,  2.7598033e+00],\n",
       "       [-2.6262093e+00,  2.5614316e+00],\n",
       "       [-2.8468959e+00,  2.7565684e+00],\n",
       "       [ 2.2969551e+00, -2.1063910e+00],\n",
       "       [-2.7842722e+00,  2.7995415e+00],\n",
       "       [-2.7778301e+00,  2.7992735e+00],\n",
       "       [-2.8274996e+00,  2.7978983e+00],\n",
       "       [-2.7110965e+00,  2.6976187e+00],\n",
       "       [-2.7885077e+00,  2.7735605e+00],\n",
       "       [-2.8477075e+00,  2.7734101e+00],\n",
       "       [-2.8280439e+00,  2.7929919e+00],\n",
       "       [-2.7709942e+00,  2.7723973e+00],\n",
       "       [ 2.6882291e-01, -3.3444661e-01],\n",
       "       [ 1.2802231e+00, -1.6033573e+00],\n",
       "       [-2.0868027e+00,  1.8810643e+00],\n",
       "       [-2.7998011e+00,  2.7451305e+00],\n",
       "       [-2.5891998e+00,  2.5655165e+00],\n",
       "       [ 2.7934570e+00, -2.9546785e+00],\n",
       "       [ 6.6232890e-01, -4.2923975e-01],\n",
       "       [-2.7353532e+00,  2.6062696e+00],\n",
       "       [-2.7838273e+00,  2.7489088e+00],\n",
       "       [ 2.5460000e+00, -2.5691946e+00],\n",
       "       [-2.6032844e+00,  2.5570083e+00],\n",
       "       [-2.6069324e+00,  2.4450514e+00],\n",
       "       [-2.8274062e+00,  2.7704203e+00],\n",
       "       [-2.8234339e+00,  2.8005211e+00],\n",
       "       [-2.7272105e+00,  2.6100945e+00],\n",
       "       [-2.7566500e+00,  2.7189744e+00],\n",
       "       [-2.8169777e+00,  2.7519572e+00],\n",
       "       [-2.7700522e+00,  2.7645960e+00],\n",
       "       [-2.7832694e+00,  2.7366354e+00],\n",
       "       [ 2.1032827e+00, -2.2900610e+00],\n",
       "       [ 2.4913077e+00, -2.5319974e+00],\n",
       "       [-2.6320920e+00,  2.3708394e+00],\n",
       "       [ 1.8143414e+00, -1.6765511e+00],\n",
       "       [ 2.7108574e+00, -2.9828427e+00],\n",
       "       [-2.7592485e+00,  2.7814617e+00],\n",
       "       [-2.8112538e+00,  2.7852244e+00],\n",
       "       [-2.6225531e+00,  2.2914450e+00],\n",
       "       [ 5.0404739e-01, -1.0527461e+00],\n",
       "       [-2.7952483e+00,  2.7215996e+00],\n",
       "       [-2.7778718e+00,  2.7412276e+00],\n",
       "       [-2.7855203e+00,  2.7910511e+00],\n",
       "       [-2.7101972e+00,  2.6653793e+00],\n",
       "       [-2.6392310e+00,  2.6495609e+00],\n",
       "       [-2.3681395e+00,  2.1685572e+00],\n",
       "       [-2.7540290e+00,  2.7339475e+00],\n",
       "       [ 2.8336635e+00, -2.9804611e+00],\n",
       "       [ 1.4943107e+00, -1.1498286e+00],\n",
       "       [-2.7984681e+00,  2.8009338e+00],\n",
       "       [ 2.2835863e+00, -2.5657382e+00],\n",
       "       [-2.8031132e+00,  2.7902021e+00],\n",
       "       [-2.8406494e+00,  2.7971094e+00],\n",
       "       [-2.8403223e+00,  2.7847738e+00],\n",
       "       [-2.7539158e+00,  2.7624695e+00],\n",
       "       [-2.7920702e+00,  2.7742290e+00],\n",
       "       [-2.7394452e+00,  2.7381136e+00],\n",
       "       [-2.3054981e+00,  2.2439141e+00],\n",
       "       [-2.7307849e+00,  2.5750515e+00],\n",
       "       [ 2.8366494e+00, -2.8222270e+00],\n",
       "       [-2.8073103e+00,  2.7625427e+00],\n",
       "       [-2.8066847e+00,  2.6793773e+00],\n",
       "       [-2.7556713e+00,  2.6193547e+00],\n",
       "       [ 2.6819289e+00, -2.6126049e+00],\n",
       "       [ 1.9495029e+00, -1.6501201e+00],\n",
       "       [-2.8299274e+00,  2.7659867e+00],\n",
       "       [-2.8068278e+00,  2.7672179e+00],\n",
       "       [-2.5035131e+00,  2.2715251e+00],\n",
       "       [-2.7848876e+00,  2.7951820e+00],\n",
       "       [-1.9349812e-03,  7.6798819e-02],\n",
       "       [-2.7314363e+00,  2.7174280e+00],\n",
       "       [ 2.4232101e+00, -2.5249918e+00],\n",
       "       [-2.8215251e+00,  2.8037314e+00],\n",
       "       [-2.8064880e+00,  2.7335305e+00],\n",
       "       [-2.7984037e+00,  2.7520673e+00],\n",
       "       [ 2.8097320e+00, -2.8859851e+00],\n",
       "       [ 1.5699415e+00, -1.8052565e+00],\n",
       "       [-2.8066750e+00,  2.6144862e+00],\n",
       "       [-2.7983618e+00,  2.7953267e+00],\n",
       "       [-2.5996745e+00,  2.4391358e+00],\n",
       "       [-2.7786384e+00,  2.7917747e+00],\n",
       "       [-2.7741623e+00,  2.7889643e+00],\n",
       "       [-2.7663455e+00,  2.7032709e+00],\n",
       "       [ 2.0066450e+00, -1.8951416e+00],\n",
       "       [-2.7329838e+00,  2.7587888e+00],\n",
       "       [-2.8335211e+00,  2.7917745e+00],\n",
       "       [ 2.7969117e+00, -3.0758271e+00],\n",
       "       [-2.7779300e+00,  2.8039656e+00],\n",
       "       [ 2.7733965e+00, -2.8524785e+00],\n",
       "       [-2.7462926e+00,  2.6920006e+00],\n",
       "       [-2.8036103e+00,  2.7937863e+00],\n",
       "       [-2.8134401e+00,  2.7858074e+00],\n",
       "       [-4.1140974e-02, -3.7282321e-01],\n",
       "       [ 2.2983010e+00, -2.5350683e+00],\n",
       "       [-2.7917423e+00,  2.8001246e+00],\n",
       "       [ 1.7554182e+00, -1.4535451e+00],\n",
       "       [-2.5667670e+00,  2.4857028e+00],\n",
       "       [-2.7870917e+00,  2.7272737e+00],\n",
       "       [ 2.3654952e+00, -2.5755928e+00],\n",
       "       [-1.7374973e-01,  3.2010585e-01],\n",
       "       [ 2.7100430e+00, -3.0461862e+00],\n",
       "       [ 2.7330077e+00, -2.8107700e+00],\n",
       "       [ 2.4284816e+00, -2.1575844e+00],\n",
       "       [-2.6974840e+00,  2.6335194e+00],\n",
       "       [-2.3843896e+00,  2.1686668e+00],\n",
       "       [-2.7595985e+00,  2.8004091e+00],\n",
       "       [-2.6321795e+00,  2.5638649e+00],\n",
       "       [-2.7376323e+00,  2.7817912e+00],\n",
       "       [-2.7677343e+00,  2.5817909e+00],\n",
       "       [-2.4318831e+00,  2.2911909e+00],\n",
       "       [-2.7647579e+00,  2.7885695e+00],\n",
       "       [-2.7924149e+00,  2.8038120e+00],\n",
       "       [ 2.1562130e+00, -2.3286078e+00],\n",
       "       [-2.8052709e+00,  2.6317730e+00],\n",
       "       [-2.7869973e+00,  2.7879083e+00],\n",
       "       [-2.5805328e+00,  2.4473867e+00],\n",
       "       [-2.8467636e+00,  2.7948756e+00],\n",
       "       [-2.7873299e+00,  2.7943940e+00],\n",
       "       [ 2.8346281e+00, -3.0360000e+00],\n",
       "       [-2.7439981e+00,  2.6470969e+00],\n",
       "       [-2.8343267e+00,  2.7539780e+00],\n",
       "       [-2.7595532e+00,  2.7777796e+00],\n",
       "       [ 2.6684144e+00, -2.9348748e+00],\n",
       "       [-1.0519879e+00,  1.0810198e+00],\n",
       "       [-2.8059118e+00,  2.7864263e+00],\n",
       "       [-2.7974427e+00,  2.7853563e+00],\n",
       "       [-2.7872927e+00,  2.7962549e+00],\n",
       "       [-2.7804971e+00,  2.8029680e+00],\n",
       "       [-2.7746272e+00,  2.6241591e+00],\n",
       "       [-2.7946892e+00,  2.7596791e+00],\n",
       "       [ 2.9939582e+00, -3.0533986e+00],\n",
       "       [-2.7489302e+00,  2.7958105e+00],\n",
       "       [-2.2622156e+00,  2.1731696e+00],\n",
       "       [-1.3362645e-01,  3.3356962e-01],\n",
       "       [ 2.6872437e+00, -2.6559734e+00],\n",
       "       [-2.1791790e+00,  2.0185966e+00],\n",
       "       [-2.8071179e+00,  2.8042445e+00],\n",
       "       [-2.7549105e+00,  2.7095835e+00],\n",
       "       [-2.6648481e+00,  2.6951716e+00],\n",
       "       [-2.8326588e+00,  2.7700446e+00],\n",
       "       [ 1.7272104e+00, -2.1080055e+00],\n",
       "       [-2.7632284e+00,  2.7442129e+00],\n",
       "       [-2.7769763e+00,  2.7912552e+00],\n",
       "       [-1.1155033e+00,  1.0519979e+00],\n",
       "       [-2.7374001e+00,  2.7452335e+00],\n",
       "       [-2.7333746e+00,  2.7743785e+00],\n",
       "       [-2.7440486e+00,  2.6906571e+00],\n",
       "       [-2.2396100e+00,  2.1287396e+00],\n",
       "       [ 2.4168959e+00, -2.6414955e+00],\n",
       "       [ 2.3742096e+00, -2.6425786e+00],\n",
       "       [-2.7635162e+00,  2.7433085e+00],\n",
       "       [-2.8060901e+00,  2.7936842e+00],\n",
       "       [-2.7710092e+00,  2.7934513e+00],\n",
       "       [-2.6542592e+00,  2.5767729e+00],\n",
       "       [ 1.1002221e+00, -1.2386702e+00],\n",
       "       [ 1.7750205e+00, -1.3826902e+00],\n",
       "       [ 3.7686071e-01, -3.6591938e-01],\n",
       "       [ 2.8070002e+00, -2.7862020e+00],\n",
       "       [-2.8412540e+00,  2.7475185e+00],\n",
       "       [-2.8256199e+00,  2.7940319e+00],\n",
       "       [-2.7607396e+00,  2.7581680e+00],\n",
       "       [-2.7901790e+00,  2.7896295e+00],\n",
       "       [-1.7762277e-01,  2.9281306e-01],\n",
       "       [-2.7669470e+00,  2.7932386e+00],\n",
       "       [-2.7097673e+00,  2.5100136e+00],\n",
       "       [-1.7570869e+00,  1.6902231e+00],\n",
       "       [-2.7388022e+00,  2.7187786e+00],\n",
       "       [-2.1819301e+00,  1.7737583e+00],\n",
       "       [-2.7996421e+00,  2.7971230e+00],\n",
       "       [ 2.3819401e+00, -2.2305541e+00],\n",
       "       [-2.8094196e+00,  2.7967446e+00],\n",
       "       [-2.3480380e+00,  2.0889473e+00],\n",
       "       [-2.7912235e+00,  2.7885766e+00],\n",
       "       [-2.7765000e+00,  2.7895148e+00],\n",
       "       [-2.6613190e+00,  2.6916401e+00],\n",
       "       [-2.3498118e+00,  2.2786293e+00],\n",
       "       [-2.7755115e+00,  2.7998943e+00],\n",
       "       [-2.0379810e+00,  1.7479635e+00],\n",
       "       [-2.7729492e+00,  2.7484062e+00],\n",
       "       [-2.7800825e+00,  2.7876019e+00],\n",
       "       [ 2.5402164e+00, -2.3393350e+00],\n",
       "       [-2.7990758e+00,  2.7984340e+00],\n",
       "       [-2.7595925e+00,  2.7022681e+00],\n",
       "       [ 2.6610954e+00, -2.7585893e+00],\n",
       "       [-2.8237605e-01,  1.4701006e-01],\n",
       "       [-2.7606583e+00,  2.7926188e+00],\n",
       "       [ 2.1120274e+00, -1.9838449e+00],\n",
       "       [-2.8007259e+00,  2.7663059e+00]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.5986325144767761, 'test_runtime': 2.5757, 'test_samples_per_second': 158.402, 'test_steps_per_second': 10.094})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfd11ae-8f14-415e-b5a5-2616ce33572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc0895d-a2a5-4975-a601-633aeaef3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: evaluate in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (1.26.1)\n",
      "Requirement already satisfied: dill in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.16.4\n",
      "    Uninstalling huggingface-hub-0.16.4:\n",
      "      Successfully uninstalled huggingface-hub-0.16.4\n",
      "Successfully installed huggingface-hub-0.19.4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install sklearn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03bb8bc-4dad-4ca3-9c9e-0a3faa8aad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8553921568627451, 'f1': 0.899488926746167}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"glue\",\"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f089a077-1180-4eb8-817d-131ea513500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\",\"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dbe4226-2b51-41d6-97ee-ec0cb9006a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\",evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2570f4a-d611-4255-b2bc-9b627e32fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d869bc6c-7e93-4c88-9c35-5904a15d4be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 03:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.358635</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.894366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.489262</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.886700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>0.585484</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.895726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cybertron/anaconda3/envs/llava/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.3027944703033005, metrics={'train_runtime': 182.0044, 'train_samples_per_second': 60.46, 'train_steps_per_second': 3.791, 'total_flos': 430433242128000.0, 'train_loss': 0.3027944703033005, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3fdb6-c8e5-40b4-8f8f-af8c97458ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109751e-7f6d-428b-ac0e-39de36aba775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e16e3d-b01a-4d68-9310-ca0fcfb3f7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
